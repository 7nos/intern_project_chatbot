{
  "model_info": {
    "subject": "mathematics",
    "size": "1B",
    "accuracy": 89,
    "epochs": 3,
    "batchSize": 4,
    "learningRate": 0.0002,
    "useUnsloth": true,
    "useLoRA": true,
    "createdAt": "2025-07-30T14:18:12.461Z",
    "trainingTime": 99225
  },
  "model_config": {
    "modelSize": "1B",
    "epochs": 3,
    "batchSize": 4,
    "learningRate": 0.0002,
    "useUnsloth": true,
    "useLoRA": true,
    "trainingMode": "resume",
    "baseModel": null,
    "checkpointId": "mathematics_epoch_2_step_500",
    "resumeFromCheckpoint": true,
    "transferFromSubject": null,
    "retrainExisting": false
  },
  "training_summary": {
    "subject": "mathematics",
    "model_size": "1B",
    "accuracy": "89%",
    "training_time": "99s",
    "epochs_completed": 3,
    "final_loss": "0.4484"
  },
  "readme": "# Mathematics Language Model\n\n## Model Details\n- **Subject**: mathematics\n- **Parameters**: 1B\n- **Accuracy**: 89%\n- **Training Time**: 99 seconds\n- **Epochs**: 3\n- **Batch Size**: 4\n- **Learning Rate**: 0.0002\n- **Unsloth**: Enabled\n- **LoRA**: Enabled\n\n## Usage\nThis model is specialized for mathematics-related queries and conversations.\n\n## Generated by\nLLM Training Dashboard - 2025-07-30T14:18:12.468Z",
  "model_files": {
    "description": "In a production environment, this would contain:",
    "files": [
      "model.safetensors - The trained model weights",
      "config.json - Model configuration",
      "tokenizer.json - Tokenizer configuration",
      "tokenizer_config.json - Tokenizer settings",
      "training_args.json - Training arguments used",
      "README.md - Model documentation"
    ]
  },
  "download_info": {
    "downloaded_at": "2025-07-30T14:18:12.468Z",
    "format": "Model Information Package",
    "note": "This is a demonstration package. In production, this would be a complete model archive."
  }
}