{
  "model_info": {
    "subject": "mathematics",
    "size": "1B",
    "accuracy": 88,
    "epochs": 3,
    "batchSize": 4,
    "learningRate": 0.0002,
    "useUnsloth": true,
    "useLoRA": true,
    "createdAt": "2025-07-30T12:55:43.190Z",
    "trainingTime": 121563
  },
  "model_config": {
    "modelSize": "1B",
    "epochs": 3,
    "batchSize": 4,
    "learningRate": 0.0002,
    "useUnsloth": true,
    "useLoRA": true,
    "trainingMode": "fine_tune",
    "baseModel": null,
    "checkpointId": null,
    "resumeFromCheckpoint": false,
    "transferFromSubject": null,
    "retrainExisting": false,
    "dataSource": "database",
    "dataFormat": "custom",
    "dataValidation": {
      "isValid": true,
      "errors": [],
      "warnings": [],
      "statistics": {
        "totalItems": 1,
        "fieldAnalysis": {}
      },
      "cleanedData": [
        {
          "id": 0,
          "eno": 21,
          "ename": "solomonMatthews",
          "salary": 250000
        }
      ]
    },
    "dataConfig": {
      "database": {
        "port": 3306,
        "database": "aiml",
        "username": "root",
        "password": "root"
      },
      "extraction": {
        "table": "emp"
      }
    },
    "customModel": null,
    "ollamaModel": {
      "id": "ollama_smollm_360m",
      "name": "smollm:360m",
      "size": "218.52 MB",
      "modified": "2025-07-30T18:12:55.609035+05:30",
      "digest": "b3ba1ccba2b80fe98c3b00798a95228d709b6ba86f15b483a4011b05fa2afe29",
      "type": "ollama",
      "source": "ollama",
      "compatible_subjects": [
        "general",
        "science",
        "mathematics",
        "programming",
        "literature"
      ],
      "description": "Local language model available through Ollama",
      "parameters": "70B+"
    }
  },
  "training_summary": {
    "subject": "mathematics",
    "model_size": "1B",
    "accuracy": "88%",
    "training_time": "122s",
    "epochs_completed": 3,
    "final_loss": "0.7795"
  },
  "readme": "# Mathematics Language Model\n\n## Model Details\n- **Subject**: mathematics\n- **Parameters**: 1B\n- **Accuracy**: 88%\n- **Training Time**: 122 seconds\n- **Epochs**: 3\n- **Batch Size**: 4\n- **Learning Rate**: 0.0002\n- **Unsloth**: Enabled\n- **LoRA**: Enabled\n\n## Usage\nThis model is specialized for mathematics-related queries and conversations.\n\n## Generated by\nLLM Training Dashboard - 2025-07-30T12:55:43.199Z",
  "model_files": {
    "description": "In a production environment, this would contain:",
    "files": [
      "model.safetensors - The trained model weights",
      "config.json - Model configuration",
      "tokenizer.json - Tokenizer configuration",
      "tokenizer_config.json - Tokenizer settings",
      "training_args.json - Training arguments used",
      "README.md - Model documentation"
    ]
  },
  "download_info": {
    "downloaded_at": "2025-07-30T12:55:43.199Z",
    "format": "Model Information Package",
    "note": "This is a demonstration package. In production, this would be a complete model archive."
  }
}